{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset ML Addendum\n",
    "Kasey Cox / March 2018\n",
    "\n",
    "### Question: Did a passenger survive the sinking of the Titanic or not?\n",
    "My previous exploration of the Titanic dataset -- finding which passenger characteristics correlate with survival -- will serve as a basis for feature selection in this addendum.\n",
    "\n",
    "For this part of the project, a machine learning algorithm will be developed and deployed to predict which passengers survived the sinking of the Titanic.\n",
    "\n",
    "### Final output\n",
    "_From Kaggle.com_:  \n",
    "> You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.  \n",
    "> \n",
    "> The file should have exactly 2 columns:  \n",
    "> - PassengerId (sorted in any order)  \n",
    "> - Survived (contains your binary predictions: 1 for survived, 0 for deceased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "# General imports and settings\n",
    "%autosave 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Strategy\n",
    "\n",
    "1. Import and investigate (provided) train and test sets.\n",
    "2. Feature selection\n",
    "    - Use previous exploration to inform choices\n",
    "3. Feature engineering\n",
    "    - As appropriate\n",
    "4. Select a classifier\n",
    "    - Try and test (accuracy, precision, recall) classifiers\n",
    "5. Dump predictions as csv\n",
    "\n",
    "### 1. Import and investigate (provided) train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (891, 12) \n",
      "Index([u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age',\n",
      "       u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object') \n",
      "12 \n",
      "\n",
      "test: (418, 11) \n",
      "Index([u'PassengerId', u'Pclass', u'Name', u'Sex', u'Age', u'SibSp', u'Parch',\n",
      "       u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object') \n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Import train.csv and test.csv as Pandas DataFrames\n",
    "train_df = pd.read_csv('train.csv', header=0)\n",
    "print \"train:\", train_df.shape, \"\\n\", train_df.columns, \"\\n\", len(train_df.columns), \"\\n\"\n",
    "\n",
    "test_df = pd.read_csv('test.csv', header=0)\n",
    "print \"test:\", test_df.shape, \"\\n\", test_df.columns, \"\\n\", len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PassengerId', u'Survived', u'Class', u'Name', u'Sex', u'Age',\n",
      "       u'Siblings_spouses_aboard', u'Parents_children_aboard', u'Ticket',\n",
      "       u'Fare', u'Cabin_num', u'Port_of_Embarkation'],\n",
      "      dtype='object') \n",
      "12 \n",
      "\n",
      "Index([u'PassengerId', u'Class', u'Name', u'Sex', u'Age',\n",
      "       u'Siblings_spouses_aboard', u'Parents_children_aboard', u'Ticket',\n",
      "       u'Fare', u'Cabin_num', u'Port_of_Embarkation'],\n",
      "      dtype='object') \n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Rename some features to make meaning more clear\n",
    "new_train_cols = ['PassengerId', 'Survived', 'Class', 'Name', 'Sex', 'Age',\n",
    "       'Siblings_spouses_aboard', 'Parents_children_aboard', 'Ticket', 'Fare', 'Cabin_num', 'Port_of_Embarkation']\n",
    "train_df.columns = new_train_cols\n",
    "print train_df.columns, \"\\n\", len(train_df.columns), \"\\n\"\n",
    "\n",
    "new_test_cols = ['PassengerId', 'Class', 'Name', 'Sex', 'Age',\n",
    "       'Siblings_spouses_aboard', 'Parents_children_aboard', 'Ticket', 'Fare', 'Cabin_num', 'Port_of_Embarkation']\n",
    "test_df.columns = new_test_cols\n",
    "print test_df.columns, \"\\n\", len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] \n",
      "\n",
      "Distribution:\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of Survived in training set\n",
    "print train_df['Survived'].unique(), \"\\n\"\n",
    "\n",
    "print \"Distribution:\\n\", train_df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in training set features:\n",
      "PassengerId                  0\n",
      "Survived                     0\n",
      "Class                        0\n",
      "Name                         0\n",
      "Sex                          0\n",
      "Age                        177\n",
      "Siblings_spouses_aboard      0\n",
      "Parents_children_aboard      0\n",
      "Ticket                       0\n",
      "Fare                         0\n",
      "Cabin_num                  687\n",
      "Port_of_Embarkation          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in training\n",
    "print \"NaNs in training set features:\"\n",
    "print train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age did not correlate with survival, so it does not matter that there are many missing values since we will not select it as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in test set features:\n",
      "PassengerId                  0\n",
      "Class                        0\n",
      "Name                         0\n",
      "Sex                          0\n",
      "Age                         86\n",
      "Siblings_spouses_aboard      0\n",
      "Parents_children_aboard      0\n",
      "Ticket                       0\n",
      "Fare                         1\n",
      "Cabin_num                  327\n",
      "Port_of_Embarkation          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in test\n",
    "print \"NaNs in test set features:\"\n",
    "print test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature selection\n",
    "Based on work from previous investigation and the lack of missing values in the training and test data sets, I will be selecting the following features:\n",
    "1. `Sex`\n",
    "2. `Class`\n",
    "3. `Fare`\n",
    "\n",
    "**Note 1:** because `Sex` is a string, it must be converted to a numerical value for scikit-learn to accept it. 0 will correspond to `male` and 1 will correspond to `female`. Both the training and testing sets will undergo this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Sex, dtype: int64\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: Sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Transforming 'Sex' column values\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Checking that it worked...\n",
    "print train_df['Sex'].head()\n",
    "print test_df['Sex'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 2:** Because in the test set `Fare` contains a missing value (NaN), it will not work as is with scikit-learn's classes' fitting methods. I am putting the average `Fare` of those in the same `Class` in place of the NaN since it will likely reflect what the true `Fare` might be (`Fare` and `Class` are related). Because it is only one data point, this should not heavily influence the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings_spouses_aboard</th>\n",
       "      <th>Parents_children_aboard</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_num</th>\n",
       "      <th>Port_of_Embarkation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Class                Name  Sex   Age  \\\n",
       "152         1044      3  Storey, Mr. Thomas    0  60.5   \n",
       "\n",
       "     Siblings_spouses_aboard  Parents_children_aboard Ticket  Fare Cabin_num  \\\n",
       "152                        0                        0   3701   NaN       NaN   \n",
       "\n",
       "    Port_of_Embarkation  \n",
       "152                   S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The row with the NaN\n",
    "test_df[test_df['PassengerId'] == 1044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace\n",
    "test_df.loc[152, 'Fare'] = test_df['Fare'].mean()\n",
    "\n",
    "# Correct Sex and Class back to integer type\n",
    "test_df['Sex'] = test_df['Sex'].apply(int)\n",
    "test_df['Class'] = test_df['Class'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings_spouses_aboard</th>\n",
       "      <th>Parents_children_aboard</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_num</th>\n",
       "      <th>Port_of_Embarkation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>35.627188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Class                Name  Sex   Age  \\\n",
       "152         1044      3  Storey, Mr. Thomas    0  60.5   \n",
       "\n",
       "     Siblings_spouses_aboard  Parents_children_aboard Ticket       Fare  \\\n",
       "152                        0                        0   3701  35.627188   \n",
       "\n",
       "    Cabin_num Port_of_Embarkation  \n",
       "152       NaN                   S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that it worked...\n",
    "test_df[test_df['PassengerId'] == 1044]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering\n",
    "No feature engineering seems appropriate at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select a classifier\n",
    "In this step, try and evaluate (cross-validate) classifiers.\n",
    "\n",
    "For splitting into training and validation sets (from the original training data), I am simply using scikit-learn's `train_test_split` splitter function. Something more complicated like `StratifiedShuffleSplit` is not necessay because there isn't an overly skewed distribution of survival status in the original training data.\n",
    "\n",
    "_However_, because each random state is random in `train_test_split`, there could be splits that are heavily skewed. For that reason, precision and recall are useful metrics here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features to use\n",
    "features = ['Sex', 'Fare', 'Class']\n",
    "\n",
    "# Build both a features data array and a labels array (to be given to sklearn classes)\n",
    "def extract_features_labels(df, features, include_survived=False):\n",
    "    \"\"\"\n",
    "    Takes training data as a Pandas DataFrame (df) and a list of features as strings (features).\n",
    "    \n",
    "    Extracts desired features from each record and the label.\n",
    "    \n",
    "    Returns two np.array: a features data array and a labels array.\n",
    "    \"\"\"\n",
    "    feat_data_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # include 'Survived' labels\n",
    "    if include_survived != False:\n",
    "        for record in df.iterrows():\n",
    "            temp_list = []\n",
    "            for feature in (['Survived'] + features):\n",
    "                if feature == 'Survived':\n",
    "                    # Label\n",
    "                    labels_list.append(record[1][feature])\n",
    "                else:\n",
    "                    # Feature\n",
    "                    temp_list.append(record[1][feature])\n",
    "\n",
    "            # Add this record's features data to feat_data_list\n",
    "            feat_data_list.append(temp_list)\n",
    "\n",
    "        return feat_data_list, labels_list\n",
    "    \n",
    "    # do not include 'Survived' labels\n",
    "    else:\n",
    "        for record in df.iterrows():\n",
    "            temp_list = []\n",
    "            for feature in (features):\n",
    "                # Feature\n",
    "                temp_list.append(record[1][feature])\n",
    "\n",
    "            # Add this record's features data to feat_data_list\n",
    "            feat_data_list.append(temp_list)\n",
    "\n",
    "        return feat_data_list, None\n",
    "        \n",
    "\n",
    "# Extract the features and labels from the training set\n",
    "features_data, labels = extract_features_labels(train_df, features, include_survived=True)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_data, labels, test_size = 0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.757847533632\n",
      "Recall: 0.688888888889\n",
      "Precision: 0.704545454545\n"
     ]
    }
   ],
   "source": [
    "# Fit classifier with training set\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate with validation set\n",
    "print \"Score:\", nb_clf.score(X_val, y_val)\n",
    "print \"Recall:\", recall_score(y_val, nb_clf.predict(X_val))\n",
    "print \"Precision:\", precision_score(y_val, nb_clf.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 5, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV (parameter tuning)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf_to_tune = DecisionTreeClassifier()\n",
    "parameters = {'min_samples_split':(2, 3, 4, 5, 6), 'max_depth':(None, 5, 10, 15, 20)}\n",
    "cv_clf = GridSearchCV(clf_to_tune, parameters)\n",
    "cv_clf.fit(X_train, y_train)\n",
    "print cv_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.820627802691\n",
      "Recall: 0.7\n",
      "Precision: 0.828947368421\n"
     ]
    }
   ],
   "source": [
    "# Fit classifier with training set\n",
    "dt_clf = DecisionTreeClassifier(min_samples_split=5, max_depth=10)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate with validation set\n",
    "print \"Score:\", dt_clf.score(X_val, y_val)\n",
    "print \"Recall:\", recall_score(y_val, dt_clf.predict(X_val))\n",
    "print \"Precision:\", precision_score(y_val, dt_clf.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correct PassengerId back to integer type\n",
    "train_df['PassengerId'] = train_df['PassengerId'].apply(int)\n",
    "test_df['PassengerId'] = test_df['PassengerId'].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dump predictions as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, labels = extract_features_labels(test_df, features, include_survived=False)\n",
    "\n",
    "preds = dt_clf.predict(data)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': preds})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
